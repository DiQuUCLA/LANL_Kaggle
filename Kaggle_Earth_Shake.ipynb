{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from scipy.signal import hann\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import convolve\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, RepeatedKFold\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_train_data = pd.read_csv(\"train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignial Dataset contains 629145480 rows, 2 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Orignial Dataset contains {} rows, {} columns\"\n",
    "      .format(origin_train_data.shape[0], origin_train_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset contain 4194.0 segments\n"
     ]
    }
   ],
   "source": [
    "segments = np.floor(origin_train_data.shape[0] / 150000)\n",
    "print(\"The original dataset contain {} segments\".format(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapped_seg_begin_point(data_length, skipping = 150000, window_size = 150000):\n",
    "    last_valid_pos = data_length - data_length % window_size - window_size + 1\n",
    "    return list(range(0, last_valid_pos, skipping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_poses = get_overlapped_seg_begin_point(origin_train_data.shape[0], 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_values:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    sta = np.cumsum(x ** 2)\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "    # Pad zeros\n",
    "    sta[:length_lta - 1] = 0\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "    return sta / lta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(seg_id, seg, X):\n",
    "    xc = pd.Series(seg['acoustic_data'].values)\n",
    "    \n",
    "    X.loc[seg_id, 'mean'] = xc.mean()\n",
    "    X.loc[seg_id, 'std'] = xc.std()\n",
    "    X.loc[seg_id, 'max'] = xc.max()\n",
    "    X.loc[seg_id, 'min'] = xc.min()\n",
    "    \n",
    "    X.loc[seg_id, 'mean_change_abs'] = np.mean(np.diff(xc))\n",
    "    X.loc[seg_id, 'mean_change_rate'] = np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0])\n",
    "    X.loc[seg_id, 'abs_max'] = np.abs(xc).max()\n",
    "    X.loc[seg_id, 'abs_min'] = np.abs(xc).min()\n",
    "    \n",
    "    X.loc[seg_id, 'std_first_50000'] = xc[:50000].std()\n",
    "    X.loc[seg_id, 'std_last_50000'] = xc[-50000:].std()\n",
    "    X.loc[seg_id, 'std_first_10000'] = xc[:10000].std()\n",
    "    X.loc[seg_id, 'std_last_10000'] = xc[-10000:].std()\n",
    "    \n",
    "    X.loc[seg_id, 'avg_first_50000'] = xc[:50000].mean()\n",
    "    X.loc[seg_id, 'avg_last_50000'] = xc[-50000:].mean()\n",
    "    X.loc[seg_id, 'avg_first_10000'] = xc[:10000].mean()\n",
    "    X.loc[seg_id, 'avg_last_10000'] = xc[-10000:].mean()\n",
    "    \n",
    "    X.loc[seg_id, 'min_first_50000'] = xc[:50000].min()\n",
    "    X.loc[seg_id, 'min_last_50000'] = xc[-50000:].min()\n",
    "    X.loc[seg_id, 'min_first_10000'] = xc[:10000].min()\n",
    "    X.loc[seg_id, 'min_last_10000'] = xc[-10000:].min()\n",
    "    \n",
    "    X.loc[seg_id, 'max_first_50000'] = xc[:50000].max()\n",
    "    X.loc[seg_id, 'max_last_50000'] = xc[-50000:].max()\n",
    "    X.loc[seg_id, 'max_first_10000'] = xc[:10000].max()\n",
    "    X.loc[seg_id, 'max_last_10000'] = xc[-10000:].max()\n",
    "    \n",
    "    X.loc[seg_id, 'max_to_min'] = xc.max() / np.abs(xc.min())\n",
    "    X.loc[seg_id, 'max_to_min_diff'] = xc.max() - np.abs(xc.min())\n",
    "    X.loc[seg_id, 'count_big'] = len(xc[np.abs(xc) > 500])\n",
    "    X.loc[seg_id, 'sum'] = xc.sum()\n",
    "    \n",
    "    X.loc[seg_id, 'mean_change_rate_first_50000'] = np.mean(np.nonzero((np.diff(xc[:50000]) / xc[:50000][:-1]))[0])\n",
    "    X.loc[seg_id, 'mean_change_rate_last_50000'] = np.mean(np.nonzero((np.diff(xc[-50000:]) / xc[-50000:][:-1]))[0])\n",
    "    X.loc[seg_id, 'mean_change_rate_first_10000'] = np.mean(np.nonzero((np.diff(xc[:10000]) / xc[:10000][:-1]))[0])\n",
    "    X.loc[seg_id, 'mean_change_rate_last_10000'] = np.mean(np.nonzero((np.diff(xc[-10000:]) / xc[-10000:][:-1]))[0])\n",
    "    \n",
    "    X.loc[seg_id, 'q95'] = np.quantile(xc, 0.95)\n",
    "    X.loc[seg_id, 'q99'] = np.quantile(xc, 0.99)\n",
    "    X.loc[seg_id, 'q05'] = np.quantile(xc, 0.05)\n",
    "    X.loc[seg_id, 'q01'] = np.quantile(xc, 0.01)\n",
    "    \n",
    "    X.loc[seg_id, 'abs_q95'] = np.quantile(np.abs(xc), 0.95)\n",
    "    X.loc[seg_id, 'abs_q99'] = np.quantile(np.abs(xc), 0.99)\n",
    "    X.loc[seg_id, 'abs_q05'] = np.quantile(np.abs(xc), 0.05)\n",
    "    X.loc[seg_id, 'abs_q01'] = np.quantile(np.abs(xc), 0.01)\n",
    "    \n",
    "    X.loc[seg_id, 'trend'] = add_trend_feature(xc)\n",
    "    X.loc[seg_id, 'abs_trend'] = add_trend_feature(xc, abs_values=True)\n",
    "    X.loc[seg_id, 'abs_mean'] = np.abs(xc).mean()\n",
    "    X.loc[seg_id, 'abs_std'] = np.abs(xc).std()\n",
    "    \n",
    "    X.loc[seg_id, 'mad'] = xc.mad()\n",
    "    X.loc[seg_id, 'kurt'] = xc.kurtosis()\n",
    "    X.loc[seg_id, 'skew'] = xc.skew()\n",
    "    X.loc[seg_id, 'med'] = xc.median()\n",
    "    \n",
    "    X.loc[seg_id, 'Hilbert_mean'] = np.abs(hilbert(xc)).mean()\n",
    "    X.loc[seg_id, 'Hann_window_mean'] = (convolve(xc, hann(150), mode='same') / sum(hann(150))).mean()\n",
    "    X.loc[seg_id, 'Moving_average_700_mean'] = xc.rolling(window=700).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'Moving_average_1500_mean'] = xc.rolling(window=1500).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'Moving_average_3000_mean'] = xc.rolling(window=3000).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'Moving_average_6000_mean'] = xc.rolling(window=6000).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X.loc[seg_id, 'exp_Moving_average_300_mean'] = (ewma(xc, span=300).mean()).mean(skipna=True)\n",
    "    X.loc[seg_id, 'exp_Moving_average_3000_mean'] = ewma(xc, span=3000).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'exp_Moving_average_30000_mean'] = ewma(xc, span=6000).mean().mean(skipna=True)\n",
    "    no_of_std = 2\n",
    "    X.loc[seg_id, 'MA_700MA_std_mean'] = xc.rolling(window=700).std().mean()\n",
    "    X.loc[seg_id,'MA_700MA_BB_high_mean'] = (X.loc[seg_id, 'Moving_average_700_mean'] + no_of_std * X.loc[seg_id, 'MA_700MA_std_mean']).mean()\n",
    "    X.loc[seg_id,'MA_700MA_BB_low_mean'] = (X.loc[seg_id, 'Moving_average_700_mean'] - no_of_std * X.loc[seg_id, 'MA_700MA_std_mean']).mean()\n",
    "    X.loc[seg_id, 'MA_400MA_std_mean'] = xc.rolling(window=400).std().mean()\n",
    "    X.loc[seg_id,'MA_400MA_BB_high_mean'] = (X.loc[seg_id, 'Moving_average_700_mean'] + no_of_std * X.loc[seg_id, 'MA_400MA_std_mean']).mean()\n",
    "    X.loc[seg_id,'MA_400MA_BB_low_mean'] = (X.loc[seg_id, 'Moving_average_700_mean'] - no_of_std * X.loc[seg_id, 'MA_400MA_std_mean']).mean()\n",
    "    X.loc[seg_id, 'MA_1000MA_std_mean'] = xc.rolling(window=1000).std().mean()\n",
    "    \n",
    "    X.loc[seg_id, 'iqr'] = np.subtract(*np.percentile(xc, [75, 25]))\n",
    "    X.loc[seg_id, 'q999'] = np.quantile(xc,0.999)\n",
    "    X.loc[seg_id, 'q001'] = np.quantile(xc,0.001)\n",
    "    X.loc[seg_id, 'ave10'] = stats.trim_mean(xc, 0.1)\n",
    "    \n",
    "    for windows in [10, 100, 1000]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "        \n",
    "        X.loc[seg_id, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X.loc[seg_id, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X.loc[seg_id, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X.loc[seg_id, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X.loc[seg_id, 'q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X.loc[seg_id, 'q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X.loc[seg_id, 'q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X.loc[seg_id, 'q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X.loc[seg_id, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "        X.loc[seg_id, 'av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "        X.loc[seg_id, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "        X.loc[seg_id, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X.loc[seg_id, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X.loc[seg_id, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X.loc[seg_id, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X.loc[seg_id, 'q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X.loc[seg_id, 'q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X.loc[seg_id, 'q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X.loc[seg_id, 'q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X.loc[seg_id, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "        X.loc[seg_id, 'av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "        X.loc[seg_id, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_2(seg_id, seg, X):\n",
    "    X.loc[seg_id, \"mean\"] = seg.mean()\n",
    "    X.loc[seg_id, \"std\"]  = seg.std()\n",
    "    X.loc[seg_id, \"95_quantile\"] = np.quantile(seg, 0.95)\n",
    "    X.loc[seg_id, \"50_quantile\"] = np.quantile(seg, 0.5)\n",
    "    X.loc[seg_id, \"10_quantile\"] = np.quantile(seg, 0.1)\n",
    "    X.loc[seg_id, \"5_quantile\"] = np.quantile(seg, 0.05)\n",
    "    \n",
    "    X.loc[seg_id, \"first_5000_mean\"] = seg.iloc[:5000].mean()\n",
    "    X.loc[seg_id, \"first_5000_std\"] = seg.iloc[:5000].std()\n",
    "    X.loc[seg_id, \"95_quantile_f5000\"] = np.quantile(seg.iloc[:5000], 0.95)\n",
    "    X.loc[seg_id, \"50_quantile_f5000\"] = np.quantile(seg.iloc[:5000], 0.50)\n",
    "    X.loc[seg_id, \"10_quantile_f5000\"] = np.quantile(seg.iloc[:5000], 0.10)\n",
    "    X.loc[seg_id, \"5_quantile_f5000\"]  = np.quantile(seg.iloc[:5000], 0.05)\n",
    "    \n",
    "    X.loc[seg_id, \"mid_5000_mean\"] = seg.iloc[5000:10000].mean()\n",
    "    X.loc[seg_id, \"mide_5000_std\"] = seg.iloc[5000:10000].std()\n",
    "    X.loc[seg_id, \"95_quantile_m5000\"] = np.quantile(seg.iloc[5000:10000], 0.95)\n",
    "    X.loc[seg_id, \"50_quantile_m5000\"] = np.quantile(seg.iloc[5000:10000], 0.50)\n",
    "    X.loc[seg_id, \"10_quantile_m5000\"] = np.quantile(seg.iloc[5000:10000], 0.10)\n",
    "    X.loc[seg_id, \"5_quantile_m5000\"]  = np.quantile(seg.iloc[5000:10000], 0.05)\n",
    "    \n",
    "    X.loc[seg_id, \"last_5000_mean\"] = seg.iloc[-5000:].mean()\n",
    "    X.loc[seg_id, \"last_5000_std\"] = seg.iloc[-5000:].std()\n",
    "    X.loc[seg_id, \"95_quantile_l5000\"] = np.quantile(seg.iloc[-5000:], 0.95)\n",
    "    X.loc[seg_id, \"50_quantile_l5000\"] = np.quantile(seg.iloc[-5000:], 0.50)\n",
    "    X.loc[seg_id, \"10_quantile_l5000\"] = np.quantile(seg.iloc[-5000:], 0.10)\n",
    "    X.loc[seg_id, \"5_quantile_l5000\"]  = np.quantile(seg.iloc[-5000:], 0.05)\n",
    "    \n",
    "    rolling_window_100_mean = seg.rolling(100).mean().dropna()\n",
    "    rolling_window_100_std = seg.rolling(100).std().dropna()\n",
    "    X.loc[seg_id, \"rw100_mean_mean\"] = rolling_window_100_mean.mean()\n",
    "    X.loc[seg_id, \"rw100_mean_std\"] = rolling_window_100_mean.std()\n",
    "    X.loc[seg_id, \"rw100_std_mean\"] = rolling_window_100_std.mean()\n",
    "    X.loc[seg_id, \"rw100_std_std\"] = rolling_window_100_std.std()\n",
    "    X.loc[seg_id, \"rw100_mean_diff_mean\"] = rolling_window_100_mean.diff().dropna().mean()\n",
    "    X.loc[seg_id, \"rw100_mean_diff_std\"] = rolling_window_100_mean.diff().dropna().std()\n",
    "    X.loc[seg_id, \"rw100_std_diff_mean\"] = rolling_window_100_std.diff().dropna().mean()\n",
    "    X.loc[seg_id, \"rw100_std_diff_std\"] = rolling_window_100_std.diff().dropna().std()\n",
    "    \n",
    "    rolling_window_1000_mean = seg.rolling(1000).mean().dropna()\n",
    "    rolling_window_1000_std = seg.rolling(1000).std().dropna()\n",
    "    X.loc[seg_id, \"rw1000_mean_mean\"] = rolling_window_1000_mean.mean()\n",
    "    X.loc[seg_id, \"rw1000_mean_std\"] = rolling_window_1000_mean.std()\n",
    "    X.loc[seg_id, \"rw1000_std_mean\"] = rolling_window_1000_std.mean()\n",
    "    X.loc[seg_id, \"rw1000_std_std\"] = rolling_window_1000_std.std()\n",
    "    X.loc[seg_id, \"rw1000_mean_diff_mean\"] = rolling_window_1000_mean.diff().dropna().mean()\n",
    "    X.loc[seg_id, \"rw1000_mean_diff_std\"] = rolling_window_1000_mean.diff().dropna().std()\n",
    "    X.loc[seg_id, \"rw1000_std_diff_mean\"] = rolling_window_1000_std.diff().dropna().mean()\n",
    "    X.loc[seg_id, \"rw1000_std_diff_std\"] = rolling_window_1000_std.diff().dropna().std()\n",
    "    \n",
    "    rolling_window_5000_mean = seg.rolling(5000).mean().dropna()\n",
    "    rolling_window_5000_std = seg.rolling(5000).std().dropna()\n",
    "    X.loc[seg_id, \"rw5000_mean_mean\"] = rolling_window_5000_mean.mean()\n",
    "    X.loc[seg_id, \"rw5000_mean_std\"] = rolling_window_5000_mean.std()\n",
    "    X.loc[seg_id, \"rw5000_std_mean\"] = rolling_window_5000_std.mean()\n",
    "    X.loc[seg_id, \"rw5000_std_std\"] = rolling_window_5000_std.std()\n",
    "    X.loc[seg_id, \"rw5000_mean_diff_mean\"] = rolling_window_5000_mean.diff().dropna().mean()\n",
    "    X.loc[seg_id, \"rw5000_mean_diff_std\"] = rolling_window_5000_mean.diff().dropna().std()\n",
    "    X.loc[seg_id, \"rw5000_std_diff_mean\"] = rolling_window_5000_std.diff().dropna().mean()\n",
    "    X.loc[seg_id, \"rw5000_std_diff_std\"] = rolling_window_5000_std.diff().dropna().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3975173036944458a2e7ee01cdaba74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12580), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c817878b83ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbegin_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbegin_poses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigin_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbegin_point\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m150000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcreate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time_to_failure'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_to_failure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3d8231421cb5>\u001b[0m in \u001b[0;36mcreate_features\u001b[0;34m(seg_id, seg, X)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abs_q01'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_trend_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abs_trend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_trend_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abs_mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-59eee9fe4c7d>\u001b[0m in \u001b[0;36madd_trend_feature\u001b[0;34m(arr, abs_values)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_trend_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mabs_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_X = pd.DataFrame(index=range(int(segments)), dtype=np.float64)\n",
    "train_y = pd.DataFrame(index=range(int(segments)), dtype=np.float64, columns=['time_to_failure'])\n",
    "# iterate over all segments\n",
    "for seg_id in tqdm_notebook(range(len(begin_poses))):\n",
    "    begin_point = begin_poses[seg_id]\n",
    "    seg = origin_train_data.iloc[begin_point:begin_point + 150000]\n",
    "    create_features(seg_id, seg, train_X)\n",
    "    train_y.loc[seg_id, 'time_to_failure'] = seg['time_to_failure'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46e3f134d394b07aba7e04588093f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12580), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X = pd.DataFrame(index=range(int(segments)), dtype=np.float64)\n",
    "train_y = pd.DataFrame(index=range(int(segments)), dtype=np.float64, columns=['time_to_failure'])\n",
    "# iterate over all segments\n",
    "for seg_id in tqdm_notebook(range(len(begin_poses))):\n",
    "    begin_point = begin_poses[seg_id]\n",
    "    seg = origin_train_data.iloc[begin_point:begin_point + 150000]\n",
    "    create_features_2(seg_id, seg[\"acoustic_data\"], train_X)\n",
    "    train_y.loc[seg_id, 'time_to_failure'] = seg['time_to_failure'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"./train_X with non_fft, 50000 skipping\").drop(columns=[\"Unnamed: 0\"])\n",
    "train_y = pd.read_csv(\"./train_y with non_fft, 50000 skipping\")['time_to_failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean', 'std', 'max', 'min', 'mean_change_abs', 'mean_change_rate',\n",
      "       'abs_max', 'abs_min', 'std_first_50000', 'std_last_50000',\n",
      "       ...\n",
      "       'std_roll_mean_1000', 'max_roll_mean_1000', 'min_roll_mean_1000',\n",
      "       'q01_roll_mean_1000', 'q05_roll_mean_1000', 'q95_roll_mean_1000',\n",
      "       'q99_roll_mean_1000', 'av_change_abs_roll_mean_1000',\n",
      "       'av_change_rate_roll_mean_1000', 'abs_max_roll_mean_1000'],\n",
      "      dtype='object', length=134)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Regressor from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 100 3: 1.9807034277241633\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a58382032e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "#all_crit = [\"friedman_mse\", \"mse\", \"mae\"]\n",
    "performance_map = {}\n",
    "#for crit in all_crit:\n",
    "for estimator in [100, 150, 200, 250]:\n",
    "    for depth in [3,5,8,10,15]:\n",
    "        all_res = []\n",
    "        for train_index, test_index in kf.split(train_X):\n",
    "            X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "            y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "            model = GradientBoostingRegressor(loss = 'lad', n_estimators=estimator, max_depth=depth)            \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = mean_absolute_error(y_pred, y_test)\n",
    "            print(\"mae \" + str(estimator) + \" \" + str(depth) + \": {}\".format(acc))\n",
    "            all_res.append(acc)\n",
    "        sing_res = sum(all_res) / len(all_res)\n",
    "        performance_map[crit + \" \" + str(estimator) + \" \" + str(depth)] = sing_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 100 3: 2.036027476383842\n",
      "mae 100 3: 2.0048389016980384\n",
      "mae 100 3: 1.9319344666872509\n",
      "mae 100 3: 2.0199291414959797\n",
      "mae 100 3: 1.9992133165086141\n",
      "mae 100 3: 1.929467560843402\n",
      "mae 100 3: 1.9805003043297809\n",
      "mae 100 3: 1.971274805673163\n",
      "mae 100 3: 1.9965976650213835\n",
      "mae 100 3: 2.0593125367818232\n",
      "mae 100 5: 1.9213336379331325\n",
      "mae 100 5: 1.9408464725609567\n",
      "mae 100 5: 1.901435100844496\n",
      "mae 100 5: 1.9936313886468373\n",
      "mae 100 5: 1.987283832934347\n",
      "mae 100 5: 1.9681274316078452\n",
      "mae 100 5: 1.8902146644336904\n",
      "mae 100 5: 1.9279478300278483\n",
      "mae 100 5: 2.000603452684451\n",
      "mae 100 5: 2.00789378068973\n",
      "mae 100 8: 1.8743483997611108\n",
      "mae 100 8: 1.9834236193642718\n",
      "mae 100 8: 1.862381387892857\n",
      "mae 100 8: 1.9406947384093183\n",
      "mae 100 8: 1.9966805129382845\n",
      "mae 100 8: 1.8841611642466927\n",
      "mae 100 8: 2.00267699457772\n",
      "mae 100 8: 1.8850807957570506\n",
      "mae 100 8: 1.8285944562355096\n",
      "mae 100 8: 1.9835704620722148\n",
      "mae 100 10: 1.9001885640796254\n",
      "mae 100 10: 1.907983594402614\n",
      "mae 100 10: 1.8770044994815112\n",
      "mae 100 10: 1.813305731824858\n",
      "mae 100 10: 1.9198365249840432\n",
      "mae 100 10: 1.9352813235337694\n",
      "mae 100 10: 1.8686773001140022\n",
      "mae 100 10: 1.8813818493747199\n",
      "mae 100 10: 1.90559956036754\n",
      "mae 100 10: 1.9427500418668697\n",
      "mae 100 15: 1.8699158362573587\n",
      "mae 100 15: 1.8460609236852898\n",
      "mae 100 15: 1.9181091822311385\n",
      "mae 100 15: 1.9327604728050125\n",
      "mae 100 15: 1.8481515921908709\n",
      "mae 100 15: 1.9629261230508408\n",
      "mae 100 15: 1.883854264619148\n",
      "mae 100 15: 1.79105693755816\n",
      "mae 100 15: 1.889948880231713\n",
      "mae 100 15: 1.8915239094941505\n",
      "mae 150 3: 2.057484442651844\n",
      "mae 150 3: 1.9387482486894383\n",
      "mae 150 3: 1.9897387917395197\n",
      "mae 150 3: 1.9426730493271425\n",
      "mae 150 3: 2.049551656862845\n",
      "mae 150 3: 1.953969079671408\n",
      "mae 150 3: 2.0273425219756938\n",
      "mae 150 3: 1.934528826584759\n",
      "mae 150 3: 2.0190657565350287\n",
      "mae 150 3: 1.9001472671528985\n",
      "mae 150 5: 1.8484956835568147\n",
      "mae 150 5: 1.939785354486208\n",
      "mae 150 5: 2.0605833619953775\n",
      "mae 150 5: 1.9790381212162518\n",
      "mae 150 5: 1.982038114896247\n",
      "mae 150 5: 1.860591167724126\n",
      "mae 150 5: 1.9369591346584643\n",
      "mae 150 5: 1.9332813976729106\n",
      "mae 150 5: 1.9598066190023553\n",
      "mae 150 5: 1.9042092080874509\n",
      "mae 150 8: 1.862937997135403\n",
      "mae 150 8: 1.9363879088047677\n",
      "mae 150 8: 1.9264938972393961\n",
      "mae 150 8: 1.9526805430637506\n",
      "mae 150 8: 1.9076592082398887\n",
      "mae 150 8: 1.8848904933550377\n",
      "mae 150 8: 1.8870736771530592\n",
      "mae 150 8: 1.8632469019288416\n",
      "mae 150 8: 1.9188806600896782\n",
      "mae 150 8: 1.9101607197355586\n",
      "mae 150 10: 1.9086425379626057\n",
      "mae 150 10: 1.8948364269803324\n",
      "mae 150 10: 1.900847097663298\n",
      "mae 150 10: 1.868309530095487\n",
      "mae 150 10: 1.8368741155021655\n",
      "mae 150 10: 1.9683160341186026\n",
      "mae 150 10: 1.859812034100886\n",
      "mae 150 10: 1.8471944341489108\n",
      "mae 150 10: 1.891735174129543\n",
      "mae 150 10: 1.9332014073400414\n",
      "mae 150 15: 1.9163163041711817\n",
      "mae 150 15: 1.820825817609576\n",
      "mae 150 15: 1.9658300543074405\n",
      "mae 150 15: 1.9042241176913406\n",
      "mae 150 15: 1.816583947162094\n",
      "mae 150 15: 1.8120580644634432\n",
      "mae 150 15: 1.914442780082017\n",
      "mae 150 15: 1.933414545573401\n",
      "mae 150 15: 1.8014674702084004\n",
      "mae 150 15: 1.9792666740448221\n",
      "mae 200 3: 1.9848895376658566\n",
      "mae 200 3: 2.048370704107749\n",
      "mae 200 3: 1.9633962101958464\n",
      "mae 200 3: 2.007915096851273\n",
      "mae 200 3: 1.9566767205830609\n",
      "mae 200 3: 1.9598033798011434\n",
      "mae 200 3: 1.9505849887907483\n",
      "mae 200 3: 1.9470823133793516\n",
      "mae 200 3: 2.0003357190604176\n",
      "mae 200 3: 1.9295926788572995\n",
      "mae 200 5: 1.9924204500474776\n",
      "mae 200 5: 1.8493781691644442\n",
      "mae 200 5: 1.9687643423364907\n",
      "mae 200 5: 1.9578823964597534\n",
      "mae 200 5: 1.9001216364002844\n",
      "mae 200 5: 1.9591607283556078\n",
      "mae 200 5: 1.9216831805844874\n",
      "mae 200 5: 1.9473197173723442\n",
      "mae 200 5: 1.9460089098219842\n",
      "mae 200 5: 1.9298782228517184\n",
      "mae 200 8: 1.7674977777202951\n",
      "mae 200 8: 2.004772130637855\n",
      "mae 200 8: 1.9408417912260432\n",
      "mae 200 8: 1.952886109904697\n",
      "mae 200 8: 1.8264086956586152\n",
      "mae 200 8: 1.981556840422213\n",
      "mae 200 8: 1.8582694470124281\n",
      "mae 200 8: 1.9331579533007381\n",
      "mae 200 8: 1.8378257898408743\n",
      "mae 200 8: 1.877998326645845\n",
      "mae 200 10: 1.8376432719443518\n",
      "mae 200 10: 1.8948306878512102\n",
      "mae 200 10: 1.8982300473470808\n",
      "mae 200 10: 1.921967852543386\n",
      "mae 200 10: 1.9390175729275845\n",
      "mae 200 10: 1.8733149924842318\n",
      "mae 200 10: 1.837969559481553\n",
      "mae 200 10: 1.798854072549699\n",
      "mae 200 10: 1.897355649933022\n",
      "mae 200 10: 1.9100656964155263\n",
      "mae 200 15: 1.855494788093002\n",
      "mae 200 15: 1.8158118675462256\n",
      "mae 200 15: 1.8732395881994048\n",
      "mae 200 15: 1.9039082448618874\n",
      "mae 200 15: 1.9371665123985897\n",
      "mae 200 15: 1.970828194104195\n",
      "mae 200 15: 1.9306070583155879\n",
      "mae 200 15: 1.896877227688675\n",
      "mae 200 15: 1.9133418170361782\n",
      "mae 200 15: 1.8533568184970912\n",
      "mae 250 3: 1.912445326559168\n",
      "mae 250 3: 1.9875628752190186\n",
      "mae 250 3: 1.9469442689427283\n",
      "mae 250 3: 1.945520154505294\n",
      "mae 250 3: 2.0452642640257093\n",
      "mae 250 3: 1.9513731832505234\n",
      "mae 250 3: 1.971264025204184\n",
      "mae 250 3: 1.9781483014864671\n",
      "mae 250 3: 2.0419815160284327\n",
      "mae 250 3: 1.972380973673848\n",
      "mae 250 5: 2.0606366108486958\n",
      "mae 250 5: 1.9410985071316853\n",
      "mae 250 5: 1.9790104599025657\n",
      "mae 250 5: 1.9649943725452246\n",
      "mae 250 5: 1.8595096206300683\n",
      "mae 250 5: 1.9217035119765948\n",
      "mae 250 5: 1.9668524482536882\n",
      "mae 250 5: 1.9179217796258308\n",
      "mae 250 5: 1.8436232567535558\n",
      "mae 250 5: 1.8829139796638663\n",
      "mae 250 8: 1.8877590280164394\n",
      "mae 250 8: 1.9132034494049974\n",
      "mae 250 8: 1.9385619420341393\n",
      "mae 250 8: 1.8184513900364006\n",
      "mae 250 8: 1.8986613804105228\n",
      "mae 250 8: 1.8739323596996873\n",
      "mae 250 8: 1.9029428190419135\n",
      "mae 250 8: 1.8835629846733575\n",
      "mae 250 8: 1.9180563480024986\n",
      "mae 250 8: 1.8728897235034447\n",
      "mae 250 10: 1.8361693043654788\n",
      "mae 250 10: 1.9236781313961082\n",
      "mae 250 10: 1.899911833936102\n",
      "mae 250 10: 1.8438914039047443\n",
      "mae 250 10: 1.8970924933414999\n",
      "mae 250 10: 1.8263859331406629\n",
      "mae 250 10: 1.893954101562433\n",
      "mae 250 10: 1.8856069957165318\n",
      "mae 250 10: 1.9222516789702262\n",
      "mae 250 10: 1.8392799207437371\n",
      "mae 250 15: 1.9242209884709776\n",
      "mae 250 15: 1.8229634262063297\n",
      "mae 250 15: 1.8731253686355138\n",
      "mae 250 15: 1.8299298675982738\n",
      "mae 250 15: 1.8524870785322325\n",
      "mae 250 15: 1.8650621724688485\n",
      "mae 250 15: 1.8858499619822648\n",
      "mae 250 15: 1.924803868075439\n",
      "mae 250 15: 1.9371718487247913\n",
      "mae 250 15: 1.9535578633162118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "kf = KFold(n_splits=10,shuffle=True)\n",
    "# Feature from Kaggle without ttf\n",
    "performance_map = {}\n",
    "#for crit in all_crit:\n",
    "for estimator in [100, 150, 200, 250]:\n",
    "    for depth in [3,5,8,10,15]:\n",
    "        all_res = []\n",
    "        for train_index, test_index in kf.split(train_X):\n",
    "            X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "            y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "            model = GradientBoostingRegressor(loss = 'lad', n_estimators=estimator, max_depth=depth)            \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = mean_absolute_error(y_pred, y_test)\n",
    "            print(\"mae \" + str(estimator) + \" \" + str(depth) + \": {}\".format(acc))\n",
    "            all_res.append(acc)\n",
    "        sing_res = sum(all_res) / len(all_res)\n",
    "        performance_map[\"mae\" + \" \" + str(estimator) + \" \" + str(depth)] = sing_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae 100 3': 1.992909617542328,\n",
       " 'mae 100 5': 1.9539317592363337,\n",
       " 'mae 100 8': 1.924161253125503,\n",
       " 'mae 100 10': 1.8952008990029554,\n",
       " 'mae 100 15': 1.883430812212368,\n",
       " 'mae 150 3': 1.9813249641190578,\n",
       " 'mae 150 5': 1.9404788163296203,\n",
       " 'mae 150 8': 1.9050412006745379,\n",
       " 'mae 150 10': 1.8909768792041874,\n",
       " 'mae 150 15': 1.8864429775313714,\n",
       " 'mae 200 3': 1.9748647349292745,\n",
       " 'mae 200 5': 1.9372617753394596,\n",
       " 'mae 200 8': 1.8981214862369604,\n",
       " 'mae 200 10': 1.8809249403477648,\n",
       " 'mae 200 15': 1.8950632116740835,\n",
       " 'mae 250 3': 1.9752884888895372,\n",
       " 'mae 250 5': 1.9338264547331776,\n",
       " 'mae 250 8': 1.89080214248234,\n",
       " 'mae 250 10': 1.8768221797077527,\n",
       " 'mae 250 15': 1.8869172444010887}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 100 3: 2.161387051140885\n",
      "mae 100 3: 2.054604259042986\n",
      "mae 100 3: 2.1581014511056393\n",
      "mae 100 3: 2.212773796292269\n",
      "mae 100 3: 2.110614115467644\n",
      "mae 100 3: 2.1396863255239627\n",
      "mae 100 3: 2.2514432712498476\n",
      "mae 100 3: 2.2031328452603067\n",
      "mae 100 3: 2.081217089628747\n",
      "mae 100 3: 2.1237516525986875\n",
      "mae 100 5: 2.099740616480439\n",
      "mae 100 5: 2.1075818407858953\n",
      "mae 100 5: 2.065043470351204\n",
      "mae 100 5: 2.159921135948344\n",
      "mae 100 5: 2.1449122923165995\n",
      "mae 100 5: 2.1478832837964648\n",
      "mae 100 5: 2.0755009876833976\n",
      "mae 100 5: 2.085501346484551\n",
      "mae 100 5: 2.060753139261848\n",
      "mae 100 5: 2.100066265324292\n",
      "mae 100 8: 2.149663316319457\n",
      "mae 100 8: 2.0438438274127324\n",
      "mae 100 8: 2.048436610581725\n",
      "mae 100 8: 2.091792451991077\n",
      "mae 100 8: 1.9833956971381281\n",
      "mae 100 8: 2.0961451539917317\n",
      "mae 100 8: 2.1244267691121217\n",
      "mae 100 8: 2.0540567231038507\n",
      "mae 100 8: 2.158621319934064\n",
      "mae 100 8: 2.0770264449363616\n",
      "mae 100 10: 2.141219300892099\n",
      "mae 100 10: 2.100818888385697\n",
      "mae 100 10: 2.083874909656423\n",
      "mae 100 10: 2.0024979244137855\n",
      "mae 100 10: 2.0407284547310685\n",
      "mae 100 10: 2.1091922575529054\n",
      "mae 100 10: 2.0965653577218357\n",
      "mae 100 10: 2.1543101047853606\n",
      "mae 100 10: 2.038571709528951\n",
      "mae 100 10: 2.1005166478113635\n",
      "mae 100 15: 2.1305337896135907\n",
      "mae 100 15: 2.0681609625121293\n",
      "mae 100 15: 2.074102842510776\n",
      "mae 100 15: 2.040322970624501\n",
      "mae 100 15: 2.0631399109501802\n",
      "mae 100 15: 2.114919983495901\n",
      "mae 100 15: 2.0860873319128297\n",
      "mae 100 15: 2.1070618814164703\n",
      "mae 100 15: 2.064947716435649\n",
      "mae 100 15: 2.09541788171071\n",
      "mae 150 3: 2.209191594120752\n",
      "mae 150 3: 2.1778935445060816\n",
      "mae 150 3: 2.169482305046447\n",
      "mae 150 3: 2.140306582798013\n",
      "mae 150 3: 2.1195905746794987\n",
      "mae 150 3: 2.1558970235777983\n",
      "mae 150 3: 2.1314625288741254\n",
      "mae 150 3: 2.1574646147453964\n",
      "mae 150 3: 2.156590016145113\n",
      "mae 150 3: 2.0725556378417287\n",
      "mae 150 5: 2.041436026892396\n",
      "mae 150 5: 2.0144337606015674\n",
      "mae 150 5: 2.1658861300839103\n",
      "mae 150 5: 2.102944421680438\n",
      "mae 150 5: 2.0650472321396376\n",
      "mae 150 5: 2.0672763503648475\n",
      "mae 150 5: 2.135353360795837\n",
      "mae 150 5: 2.1654447815083264\n",
      "mae 150 5: 2.096903401771309\n",
      "mae 150 5: 2.1711976974291067\n",
      "mae 150 8: 2.0983159719608215\n",
      "mae 150 8: 2.1371754284385758\n",
      "mae 150 8: 2.0777974207754966\n",
      "mae 150 8: 2.0389564568297196\n",
      "mae 150 8: 2.102396414868657\n",
      "mae 150 8: 2.1338657015803117\n",
      "mae 150 8: 2.0271067209587383\n",
      "mae 150 8: 2.0866217616115117\n",
      "mae 150 8: 2.0626645731573574\n",
      "mae 150 8: 2.0985195467820525\n",
      "mae 150 10: 2.0983848605420024\n",
      "mae 150 10: 2.1127014383644527\n",
      "mae 150 10: 2.0442757679418606\n",
      "mae 150 10: 2.1286140452825233\n",
      "mae 150 10: 2.0793650127456913\n",
      "mae 150 10: 2.0621458131923043\n",
      "mae 150 10: 2.118578558382334\n",
      "mae 150 10: 2.065980653506988\n",
      "mae 150 10: 2.1317559823337837\n",
      "mae 150 10: 1.9707707566750303\n",
      "mae 150 15: 2.0444184971925754\n",
      "mae 150 15: 2.1282136785044563\n",
      "mae 150 15: 2.1196158638330247\n",
      "mae 150 15: 2.1046060848853125\n",
      "mae 150 15: 2.050117725603253\n",
      "mae 150 15: 2.044752324908096\n",
      "mae 150 15: 2.08208533916478\n",
      "mae 150 15: 2.113320412266787\n",
      "mae 150 15: 2.104831987572941\n",
      "mae 150 15: 2.057868479100148\n",
      "mae 200 3: 2.1264689111554365\n",
      "mae 200 3: 2.142549721835552\n",
      "mae 200 3: 2.116061653385877\n",
      "mae 200 3: 2.2067114698684747\n",
      "mae 200 3: 2.1799293695040647\n",
      "mae 200 3: 2.0756756068037427\n",
      "mae 200 3: 2.117391233772744\n",
      "mae 200 3: 2.1621456289497023\n",
      "mae 200 3: 2.176876729695601\n",
      "mae 200 3: 2.197509637816742\n",
      "mae 200 5: 2.104974895254295\n",
      "mae 200 5: 2.082155320875137\n",
      "mae 200 5: 2.1322934300061243\n",
      "mae 200 5: 2.117994547522481\n",
      "mae 200 5: 2.142904945736927\n",
      "mae 200 5: 2.1258852870525162\n",
      "mae 200 5: 2.06654220672942\n",
      "mae 200 5: 2.0935597816699363\n",
      "mae 200 5: 2.113141034803623\n",
      "mae 200 5: 2.050736980432758\n",
      "mae 200 8: 2.0607730404782982\n",
      "mae 200 8: 2.0481155224509844\n",
      "mae 200 8: 2.098594100077212\n",
      "mae 200 8: 2.11272418108041\n",
      "mae 200 8: 2.1258313173112824\n",
      "mae 200 8: 2.0148558002773918\n",
      "mae 200 8: 2.069228657242558\n",
      "mae 200 8: 2.1678123239059106\n",
      "mae 200 8: 2.115907092884736\n",
      "mae 200 8: 2.032604030372608\n",
      "mae 200 10: 2.0856918800312187\n",
      "mae 200 10: 2.0826426052794975\n",
      "mae 200 10: 2.0620557813456224\n",
      "mae 200 10: 2.091972641278779\n",
      "mae 200 10: 2.016065106832235\n",
      "mae 200 10: 2.078049370170152\n",
      "mae 200 10: 2.103190937356056\n",
      "mae 200 10: 2.106857140558039\n",
      "mae 200 10: 2.1142478883890856\n",
      "mae 200 10: 2.050197912021924\n",
      "mae 200 15: 2.1325176810937667\n",
      "mae 200 15: 2.074428300603685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-da2c9f4a32e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             model = RandomForestRegressor(max_depth=depth, random_state=0,\n\u001b[1;32m     10\u001b[0m                                                   n_estimators=estimator,)\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_RFR_result = []\n",
    "RFR_performance_map = {}\n",
    "for estimator in [100, 150, 200, 250]:\n",
    "    for depth in [3,5,8,10,15]:\n",
    "        all_RFR_result = []\n",
    "        for train_index, test_index in kf.split(train_X):\n",
    "            X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "            y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "            model = RandomForestRegressor(max_depth=depth, random_state=0,\n",
    "                                                  n_estimators=estimator,)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = mean_absolute_error(y_pred, y_test)\n",
    "            print(\"mae \" + str(estimator) + \" \" + str(depth) + \": {}\".format(acc))\n",
    "            all_RFR_result.append(acc)\n",
    "        sing_res = sum(all_RFR_result) / len(all_RFR_result)\n",
    "        RFR_performance_map[crit + \" \" + str(estimator) + \" \" + str(depth)] = sing_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'friedman_mse 100 3': 2.1496711857310977,\n",
       " 'friedman_mse 100 5': 2.1046904378433036,\n",
       " 'friedman_mse 100 8': 2.0827408314521247,\n",
       " 'friedman_mse 100 10': 2.0868295555479492,\n",
       " 'friedman_mse 100 15': 2.084469527118274,\n",
       " 'friedman_mse 150 3': 2.1490434422334954,\n",
       " 'friedman_mse 150 5': 2.1025923163267377,\n",
       " 'friedman_mse 150 8': 2.086341999696324,\n",
       " 'friedman_mse 150 10': 2.0812572888966967,\n",
       " 'friedman_mse 150 15': 2.084983039303137,\n",
       " 'friedman_mse 200 3': 2.1501319962787933,\n",
       " 'friedman_mse 200 5': 2.1030188430083214,\n",
       " 'friedman_mse 200 8': 2.084644606608139,\n",
       " 'friedman_mse 200 10': 2.079097126326261}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR_performance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(all_RFR_result) / len(all_RFR_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(X_train.keys()[model.feature_importances_.argsort()][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 100 3: 2.0469906958061395\n",
      "mae 100 3: 2.0439816628788634\n",
      "mae 100 3: 2.1065289161254093\n",
      "mae 100 3: 2.0104419259332147\n",
      "mae 100 3: 2.058890188510088\n",
      "mae 100 3: 2.0681201504707682\n",
      "mae 100 3: 2.0630779807830275\n",
      "mae 100 3: 2.1239547744051\n",
      "mae 100 3: 2.112927186569614\n",
      "mae 100 3: 2.1426240799940452\n",
      "mae 100 5: 2.076036718938432\n",
      "mae 100 5: 2.130295501509978\n",
      "mae 100 5: 1.962372352222085\n",
      "mae 100 5: 1.964847986135427\n",
      "mae 100 5: 2.11591591171807\n",
      "mae 100 5: 2.0638687311437156\n",
      "mae 100 5: 2.031378536903276\n",
      "mae 100 5: 2.0565995384280162\n",
      "mae 100 5: 2.013712403290341\n",
      "mae 100 5: 1.9734881683685856\n",
      "mae 100 8: 1.9892503542201585\n",
      "mae 100 8: 1.9656838798252643\n",
      "mae 100 8: 1.9185612997784363\n",
      "mae 100 8: 1.9874033720701518\n",
      "mae 100 8: 2.0326810929904187\n",
      "mae 100 8: 1.9891404403746396\n",
      "mae 100 8: 2.014141913353543\n",
      "mae 100 8: 1.9496976884692128\n",
      "mae 100 8: 2.0475623215256364\n",
      "mae 100 8: 2.1077118631723857\n",
      "mae 100 10: 1.906630812126869\n",
      "mae 100 10: 1.9885526019990538\n",
      "mae 100 10: 1.993176409906161\n",
      "mae 100 10: 1.9652446043394685\n",
      "mae 100 10: 2.006221522021949\n",
      "mae 100 10: 2.008133027532085\n",
      "mae 100 10: 1.9801395258740384\n",
      "mae 100 10: 2.0282769289167577\n",
      "mae 100 10: 1.986326648976097\n",
      "mae 100 10: 2.008125433917255\n",
      "mae 100 15: 1.906785275288031\n",
      "mae 100 15: 1.9523454675143321\n",
      "mae 100 15: 1.9117044028259322\n",
      "mae 100 15: 1.8853700387846737\n",
      "mae 100 15: 2.0307460547625222\n",
      "mae 100 15: 1.9991837519823443\n",
      "mae 100 15: 1.8961424430906015\n",
      "mae 100 15: 1.9877040697884212\n",
      "mae 100 15: 2.018801226476564\n",
      "mae 100 15: 1.9819200743918304\n",
      "mae 150 3: 2.060141888107306\n",
      "mae 150 3: 2.0230780001269255\n",
      "mae 150 3: 2.1890970737198026\n",
      "mae 150 3: 2.009689545134555\n",
      "mae 150 3: 2.0841692658853335\n",
      "mae 150 3: 2.0086924504570787\n",
      "mae 150 3: 2.0997858670902243\n",
      "mae 150 3: 2.044706954671573\n",
      "mae 150 3: 2.102927349345265\n",
      "mae 150 3: 2.13899749992367\n",
      "mae 150 5: 2.008854818549013\n",
      "mae 150 5: 2.0684383903393555\n",
      "mae 150 5: 1.989965779090089\n",
      "mae 150 5: 2.0578568102748034\n",
      "mae 150 5: 2.0669605702225544\n",
      "mae 150 5: 2.0284614269283683\n",
      "mae 150 5: 2.002250285611125\n",
      "mae 150 5: 1.9707409648582976\n",
      "mae 150 5: 2.053893990644512\n",
      "mae 150 5: 2.1094462542876395\n",
      "mae 150 8: 1.9488626462201628\n",
      "mae 150 8: 2.010151058785217\n",
      "mae 150 8: 1.9928394155224833\n",
      "mae 150 8: 2.0314646588329164\n",
      "mae 150 8: 2.1062056366452473\n",
      "mae 150 8: 2.0147125388818194\n",
      "mae 150 8: 2.0027644485744744\n",
      "mae 150 8: 1.9312884639447383\n",
      "mae 150 8: 2.0579222186639363\n",
      "mae 150 8: 1.9231299870846956\n",
      "mae 150 10: 2.011276689473254\n",
      "mae 150 10: 1.9262427636993142\n",
      "mae 150 10: 1.9584820325871275\n",
      "mae 150 10: 2.0058512590975535\n",
      "mae 150 10: 1.9381919669319463\n",
      "mae 150 10: 1.9990422194029824\n",
      "mae 150 10: 1.978312596780743\n",
      "mae 150 10: 2.028832880956191\n",
      "mae 150 10: 2.0027065032550966\n",
      "mae 150 10: 2.0068635587843997\n",
      "mae 150 15: 1.9583617010767636\n",
      "mae 150 15: 1.9253647015466602\n",
      "mae 150 15: 1.9977005747567016\n",
      "mae 150 15: 1.9511197711199957\n",
      "mae 150 15: 1.9036748856229033\n",
      "mae 150 15: 1.9954241865054503\n",
      "mae 150 15: 1.9312963415647597\n",
      "mae 150 15: 1.933447555396904\n",
      "mae 150 15: 1.9773461482499426\n",
      "mae 200 5: 2.040262214156165\n",
      "mae 200 5: 2.021949730436249\n",
      "mae 200 5: 2.0424800255362543\n",
      "mae 200 5: 2.0451189102161518\n",
      "mae 200 5: 1.9570548082142138\n",
      "mae 200 5: 1.9918801145457397\n",
      "mae 200 5: 2.0941182321729497\n",
      "mae 200 8: 2.0730659732651673\n",
      "mae 200 8: 1.9623635267726272\n",
      "mae 200 8: 1.9853746481762387\n",
      "mae 200 8: 1.9230124170830947\n",
      "mae 200 8: 1.9954868464066289\n",
      "mae 200 8: 2.084123420980563\n",
      "mae 200 8: 2.0075650328153065\n",
      "mae 200 8: 1.9678439576869229\n",
      "mae 200 8: 2.0171229104916257\n",
      "mae 200 8: 1.9995209730642856\n",
      "mae 200 10: 1.9527107764490583\n",
      "mae 200 10: 2.0496592842136225\n",
      "mae 200 10: 1.9445909600674314\n",
      "mae 200 10: 1.911269357065936\n",
      "mae 200 10: 1.9315490815695877\n",
      "mae 200 10: 1.949884608703687\n",
      "mae 200 10: 2.048201853067887\n",
      "mae 200 10: 1.9239549333683867\n",
      "mae 200 10: 2.0628221512813267\n",
      "mae 200 10: 2.036668070004477\n",
      "mae 200 15: 1.9675093102409336\n",
      "mae 200 15: 1.9506652605637533\n",
      "mae 200 15: 1.9717063496736738\n",
      "mae 200 15: 1.9445778332610557\n",
      "mae 200 15: 1.9328263132056334\n",
      "mae 200 15: 1.9228584077897652\n",
      "mae 200 15: 1.9706539536309415\n",
      "mae 200 15: 2.041474866684883\n",
      "mae 200 15: 1.9610184146935403\n",
      "mae 200 15: 1.9182765951364125\n",
      "mae 250 3: 2.095908749922552\n",
      "mae 250 3: 2.055055747933571\n",
      "mae 250 3: 2.1217710150751774\n",
      "mae 250 3: 2.0638066409841174\n",
      "mae 250 3: 1.9923263328520096\n",
      "mae 250 3: 2.111660662221633\n",
      "mae 250 3: 2.0021127396133895\n",
      "mae 250 3: 2.1163587259818915\n",
      "mae 250 3: 2.0904672325965787\n",
      "mae 250 3: 2.1025363590470034\n",
      "mae 250 5: 2.0251209388789264\n",
      "mae 250 5: 2.057303951016847\n",
      "mae 250 5: 2.0569476727324987\n",
      "mae 250 5: 2.0394520298751724\n",
      "mae 250 5: 1.978970655900035\n",
      "mae 250 5: 1.9251213054154304\n",
      "mae 250 5: 2.125703075359429\n",
      "mae 250 5: 2.0772312411886484\n",
      "mae 250 5: 2.0844933422498095\n",
      "mae 250 5: 2.0085143562305956\n",
      "mae 250 8: 2.005030596436583\n",
      "mae 250 8: 1.9956420998676945\n",
      "mae 250 8: 2.0301762954067675\n",
      "mae 250 8: 1.9678125636177322\n",
      "mae 250 8: 2.0782914749418504\n",
      "mae 250 8: 2.002224599504473\n",
      "mae 250 8: 1.9695135796741818\n",
      "mae 250 8: 2.0225732210991385\n",
      "mae 250 8: 2.0129495810389004\n",
      "mae 250 8: 1.9297188024701708\n",
      "mae 250 10: 1.9767093054807658\n",
      "mae 250 10: 1.9452416264290036\n"
     ]
    }
   ],
   "source": [
    "all_RFR_result = []\n",
    "RFR_performance_map = {}\n",
    "for estimator in [100, 150, 200, 250]:\n",
    "    for depth in [3,5,8,10,15]:\n",
    "        all_RFR_result = []\n",
    "        for train_index, test_index in kf.split(train_X):\n",
    "            X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "            y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "            model = RandomForestRegressor(max_depth=depth, random_state=0,\n",
    "                                                  n_estimators=estimator,)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = mean_absolute_error(y_pred, y_test)\n",
    "            print(\"mae \" + str(estimator) + \" \" + str(depth) + \": {}\".format(acc))\n",
    "            all_RFR_result.append(acc)\n",
    "        sing_res = sum(all_RFR_result) / len(all_RFR_result)\n",
    "        RFR_performance_map[\" \" + str(estimator) + \" \" + str(depth)] = sing_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nerual Network from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "in_d, H_1, H_2,H_3, H_4, D_out = train_X.shape[1], 100, 80,60,20, 1\n",
    "X_np = train_X.values\n",
    "X = torch.from_numpy(X_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = train_y.values\n",
    "y = torch.from_numpy(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_d, H_1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H_1, H_2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H_2, H_3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H_4, D_out),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.L1Loss(reduction='mean')\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in range(10000):\n",
    "    y_pred = model(X.float())\n",
    "    loss = loss_fn(y.float(), y_pred)\n",
    "    if(t%100 == 0):\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(y.float(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.530147552490234"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
